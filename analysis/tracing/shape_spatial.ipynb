{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This program calculates the spaial error and shape error between a reference image and a drawing\n",
    "- Shape Error: Measured by MSE\n",
    "- Spatial Error: Rotation, Translation, Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load dependencies and define directory hierarchy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as th\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "import sys\n",
    "import os\n",
    "from __future__ import division\n",
    "import os\n",
    "import urllib, cStringIO\n",
    "import pymongo as pm ## first establish ssh tunnel to server where database is running\n",
    "import base64\n",
    "import numpy as np\n",
    "from numpy import *\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import base64\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "from matplotlib import pylab, mlab, pyplot\n",
    "from IPython.core.pylabtools import figsize, getfigs\n",
    "plt = pyplot\n",
    "import seaborn as sns\n",
    "sns.set_context('poster')\n",
    "sns.set_style('white')\n",
    "from matplotlib.path import Path\n",
    "import matplotlib.patches as patches\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from svgpathtools import parse_path\n",
    "import svg_distance_helpers as rsh\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import SimpleITK as sitk\n",
    "#sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))\n",
    "import airlab as al\n",
    "from torch.autograd import Variable\n",
    "import affine_registration_2d as ar\n",
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory & file hierarchy\n",
    "analysis_dir = os.getcwd()\n",
    "data_dir = os.path.join(analysis_dir,\"photodraw_tracing\")\n",
    "ref_dir = os.path.join(analysis_dir, 'tracing_ref_400')\n",
    "print ref_dir\n",
    "\n",
    "loss = 'f1'\n",
    "trans_dir = os.path.join(analysis_dir, 'transformed_{}'.format(loss))\n",
    "\n",
    "canvas_side = 432 # image size\n",
    "rows, cols = canvas_side, canvas_side # the size of a given drawing image\n",
    "#tracing = ['this square','this shape', 'this circle']\n",
    "tracing = ['square','shape', 'this circle']\n",
    "data_output = 'photodraw_tracing_{}.csv'.format(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare lists for dataframe construction\n",
    "age = []\n",
    "sessionid = []\n",
    "trace_item = []\n",
    "pre_mse = []\n",
    "post_mse = []\n",
    "rotate = []\n",
    "translate = []\n",
    "scale = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate reference shapes\n",
    "really_run_this = 1\n",
    "if really_run_this:\n",
    "    ref_path = []\n",
    "    for t in tracing:\n",
    "        print t\n",
    "        fname = os.path.join(ref_dir, '{}.png'.format(t))\n",
    "        img_ref = cv2.imread(fname)\n",
    "        img_ref = rsh.color_to_num(img_ref, threshold=0, white_background=False)\n",
    "        ofname = os.path.join(ref_dir, '{}_ref.png'.format(t))\n",
    "        cv2.imwrite(ofname, 255-img_ref*255)\n",
    "        ref_path.append(ofname)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(al)\n",
    "reload(ar)\n",
    "# get tracings from the data folder\n",
    "for child_dir in os.listdir(data_dir):\n",
    "    if child_dir.startswith('CDM'):\n",
    "        child_info = child_dir.split('_')\n",
    "        c_age = int(child_info[-1].replace('age',''))\n",
    "        c_sessionid = child_info[2]\n",
    "\n",
    "        for ti, t in enumerate(tracing):\n",
    "            img_draw = os.path.join(data_dir, child_dir, '{}.png'.format(t))\n",
    "            \n",
    "            if os.path.exists(img_draw):\n",
    "                img_ref = ref_path[ti]\n",
    "                output_path = os.path.join(trans_dir, '{}_{}_wrap.png'.format(c_sessionid, t))\n",
    "                init_loss, final_loss, ro, tran, s, warped = ar.affine_reg(img_draw, img_ref, output_path)\n",
    "                #cv2.imwrite(os.path.join(trans_dir,output_path), warped.numpy()*255)\n",
    "                \n",
    "                # prepare the dataframe\n",
    "                age.append(c_age)\n",
    "                sessionid.append(c_sessionid)\n",
    "                trace_item.append(t)\n",
    "                pre_mse.append(init_loss)\n",
    "                post_mse.append(final_loss)\n",
    "                rotate.append(ro)\n",
    "                translate.append(tran)\n",
    "                scale.append(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "really_run_this = 1 \n",
    "## compile data\n",
    "if really_run_this:\n",
    "    data = pd.DataFrame([sessionid, age, trace_item, pre_mse, post_mse, rotate, translate, scale])\n",
    "    data = data.transpose()\n",
    "    data.columns = ['session_id','age', 'tracing_item', 'pre_tran', 'post_tran', 'rotate', 'translate', 'scale']\n",
    "    \n",
    "## save out the data\n",
    "data.to_csv(data_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "really_run_this = 1 \n",
    "\n",
    "if really_run_this:\n",
    "    data = pd.read_csv(data_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- X axis: Age        \n",
    "- Y axis: pre/post-mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#ylim = (0, 0.1)   # mse\n",
    "ylim = (-0.8, 0.1)\n",
    "plt.figure(figsize=(18,5))\n",
    "plt.subplots_adjust(wspace=0.3)\n",
    "\n",
    "for ti, t in enumerate(tracing):\n",
    "    age = []\n",
    "    mse_list = []\n",
    "    current_trace = data.loc[(data['tracing_item'] == t)]\n",
    "    \n",
    "    for index, row in current_trace.iterrows():\n",
    "        age.append(row['age'])\n",
    "        mse_list.append(row['pre_mse'])\n",
    "    \n",
    "    plt.subplot(1,3,ti+1)\n",
    "    h = plt.scatter(age, mse_list)\n",
    "    plt.ylabel(t +' pre-mse')\n",
    "    plt.xlabel('age')\n",
    "    plt.ylim(ylim)\n",
    "    \n",
    "plt.figure(figsize=(18,5))\n",
    "plt.subplots_adjust(wspace=0.3)\n",
    "\n",
    "for ti, t in enumerate(tracing):\n",
    "    age = []\n",
    "    mse_list = []\n",
    "    current_trace = data.loc[(data['tracing_item'] == t)]\n",
    "    \n",
    "    for index, row in current_trace.iterrows():\n",
    "        age.append(row['age'])\n",
    "        mse_list.append(row['post_mse'])\n",
    "    \n",
    "    plt.subplot(1,3,ti+1)\n",
    "    h = plt.scatter(age, mse_list)\n",
    "    plt.ylabel(t +' post-mse')\n",
    "    plt.xlabel('age')\n",
    "    plt.ylim(ylim)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- X axis: Pre-mse\n",
    "- Y axis: Post-mse  \n",
    "- Age: different colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18,5))\n",
    "plt.subplots_adjust(wspace=0.3)\n",
    "\n",
    "for ti, t in enumerate(tracing):\n",
    "    plt.subplot(1,3,ti+1)\n",
    "    plt.ylabel(t +' post-mse')\n",
    "    plt.xlabel('pre-mse')\n",
    "    plt.xlim((0.0, 0.1))\n",
    "    plt.ylim((0.0, 0.1))\n",
    "    \n",
    "    for age in range(4, 8):\n",
    "        current_trace = data.loc[(data['age'] == age) &(data['tracing_item'] == t)]\n",
    "        pre_mse_list = []\n",
    "        post_mse_list = []\n",
    "        \n",
    "        for index, row in current_trace.iterrows():\n",
    "            pre_mse_list.append(row['pre_mse'])\n",
    "            post_mse_list.append(row['post_mse'])\n",
    "\n",
    "        h = plt.scatter(pre_mse_list, post_mse_list, label='age'+str(age))\n",
    "    \n",
    "    plt.legend()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- X axis: Age        \n",
    "- Y axis: rotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18,5))\n",
    "plt.subplots_adjust(wspace=0.3)\n",
    "\n",
    "for ti, t in enumerate(tracing):\n",
    "    age = []\n",
    "    mse_list = []\n",
    "    current_trace = data.loc[(data['tracing_item'] == t)]\n",
    "    \n",
    "    for index, row in current_trace.iterrows():\n",
    "        age.append(row['age'])\n",
    "        mse_list.append(row['rotate'])\n",
    "    \n",
    "    plt.subplot(1,3,ti+1)\n",
    "    h = plt.scatter(age, mse_list)\n",
    "    plt.ylabel(t +' rotation')\n",
    "    plt.xlabel('age')\n",
    "    plt.ylim((0.0, 0.2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- X axis: Age        \n",
    "- Y axis: translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18,5))\n",
    "plt.subplots_adjust(wspace=0.3)\n",
    "\n",
    "for ti, t in enumerate(tracing):\n",
    "    age = []\n",
    "    mse_list = []\n",
    "    current_trace = data.loc[(data['tracing_item'] == t)]\n",
    "    \n",
    "    for index, row in current_trace.iterrows():\n",
    "        age.append(row['age'])\n",
    "        mse_list.append(row['translate'])\n",
    "    \n",
    "    plt.subplot(1,3,ti+1)\n",
    "    h = plt.scatter(age, mse_list)\n",
    "    plt.ylabel(t +' translation')\n",
    "    plt.xlabel('age')\n",
    "    plt.ylim((0.0, 0.25))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- X axis: Age\n",
    "- Y axis: Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18,5))\n",
    "plt.subplots_adjust(wspace=0.3)\n",
    "\n",
    "for ti, t in enumerate(tracing):\n",
    "    age = []\n",
    "    mse_list = []\n",
    "    current_trace = data.loc[(data['tracing_item'] == t)]\n",
    "    \n",
    "    for index, row in current_trace.iterrows():\n",
    "        age.append(row['age'])\n",
    "        mse_list.append(row['scale'])\n",
    "    \n",
    "    plt.subplot(1,3,ti+1)\n",
    "    h = plt.scatter(age, mse_list)\n",
    "    plt.ylabel(t +' scale')\n",
    "    plt.xlabel('age')\n",
    "    plt.ylim((0, 1.2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tracing and Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get recognition correction percentage\n",
    "recog = pd.read_csv('photodraw_recognition_ratings.csv')\n",
    "all_sessions = data.session_id.unique()\n",
    "\n",
    "data['correct'] = 0\n",
    "data['condition'] = 'None'\n",
    "\n",
    "for index, id in enumerate(all_sessions):\n",
    "    rec_col = recog.loc[(recog['sessionId'] == id)]\n",
    "    if rec_col.shape[0] == 0:\n",
    "        data.loc[data['session_id'] == id, ['correct']] = 0\n",
    "        continue\n",
    "    current_condition = rec_col['condition'].iloc[0]\n",
    "    rec_correct_percent = rec_col.loc[(rec_col['correct'])].shape[0]/rec_col.shape[0]\n",
    "    data.loc[data['session_id'] == id, ['correct']] = rec_correct_percent\n",
    "    data.loc[data['session_id'] == id, ['condition']] = current_condition\n",
    "\n",
    "data.to_csv(\"photodraw_tracing.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for ci, c in enumerate(['S','W','P']):\n",
    "    plt.figure(figsize=(18,5))\n",
    "    plt.subplots_adjust(wspace=0.3)\n",
    "    for ti, t in enumerate(tracing):\n",
    "        plt.subplot(1,3,ti+1)\n",
    "        plt.ylabel(c + ' correct percent')\n",
    "        plt.xlabel(t +' post-mse')\n",
    "        plt.xlim(0.0,0.1)\n",
    "        plt.ylim(0.0,1.0)\n",
    "        \n",
    "        for age in range(4, 8):\n",
    "            current_trace = data.loc[(data['age'] == age) &(data['tracing_item'] == t) & (data['condition'] == c)]\n",
    "            post_mse_list = []\n",
    "            correct = []\n",
    "\n",
    "            for index, row in current_trace.iterrows():\n",
    "                post_mse_list.append(row['post_mse'])\n",
    "                correct.append(row['correct'])\n",
    "\n",
    "            h = plt.scatter(post_mse_list, correct, label='age'+str(age))\n",
    "    \n",
    "        plt.legend()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate whether the overall metric captures human judgment intuitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overlap the drawing on reference images\n",
    "current_data_dir = data_dir = os.path.join(analysis_dir,\"museumstation_v4_tracing\")\n",
    "tracing = ['square', 'shape', 'this circle']\n",
    "\n",
    "overlap_dir = os.path.join(analysis_dir, 'overlap')\n",
    "# get tracings from the data folder\n",
    "for child_dir in os.listdir(current_data_dir):\n",
    "    if child_dir.startswith('cdm'):\n",
    "        child_info = child_dir.split('_')\n",
    "        #c_age = int(child_info[-1].replace('age',''))\n",
    "        c_age = child_info[-1]\n",
    "        c_sessionid = child_info[2]\n",
    "\n",
    "        for ti, t in enumerate(tracing):\n",
    "            img_draw = os.path.join(data_dir, child_dir, '{}.png'.format(t))\n",
    "            \n",
    "            if os.path.exists(img_draw):\n",
    "                img_ref = ref_path[ti]\n",
    "                if t == 'this square':\n",
    "                    t = 'square'\n",
    "                if t == 'this shape':\n",
    "                    t = 'shape'\n",
    "                output_path = '{}/{}_{}.png'.format(t, c_sessionid, c_age)\n",
    "                \n",
    "                draw = cv2.imread(img_draw).astype(int16)\n",
    "                ref = cv2.imread(img_ref).astype(int16)\n",
    "                ref[ref<255] = 150\n",
    "                draw[np.sum(draw<255,axis=2)] = [255,0,0]\n",
    "                img = np.add(draw, ref) /2\n",
    "                \n",
    "                cv2.imwrite(os.path.join(overlap_dir,output_path), img)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overlap the drawing on reference images\n",
    "current_data_dir = os.path.join(analysis_dir,\"tracing_cdm_run_v3\")\n",
    "tracing = ['square', 'shape', 'this circle']\n",
    "\n",
    "overlap_dir = os.path.join(analysis_dir, 'overlap_v3')\n",
    "if not os.path.exists(overlap_dir):\n",
    "    os.makedirs(overlap_dir)\n",
    "\n",
    "# get tracings from the data folder\n",
    "for ti, t in enumerate(tracing):\n",
    "    overlap_t = os.path.join(overlap_dir, t)\n",
    "    if not os.path.exists(overlap_t):\n",
    "        os.makedirs(overlap_t)\n",
    "        \n",
    "    t_dir = os.path.join(current_data_dir, t)\n",
    "        \n",
    "    for fname in os.listdir(t_dir):\n",
    "        if fname.startswith('age'):\n",
    "            img_draw = os.path.join(current_data_dir, t_dir, fname)\n",
    "            img_ref = ref_path[ti]\n",
    "\n",
    "            draw = cv2.imread(img_draw).astype(int16)\n",
    "            ref = cv2.imread(img_ref).astype(int16)\n",
    "            img = ref\n",
    "            img[np.sum(ref, axis=2)<255*3] = [150, 150, 150]\n",
    "            img[np.sum(draw, axis=2)<255*3] = [40, 40, 170]\n",
    "            \n",
    "\n",
    "            cv2.imwrite(os.path.join(overlap_dir,t, fname), img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "really_run_this = 1 \n",
    "data_output = 'photodraw_tracing_ncc.csv'\n",
    "if really_run_this:\n",
    "    data = pd.read_csv(data_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert three spatial errors into one single number\n",
    "# 1. normalize rotation, scaling, and translation\n",
    "data['norm_r'] = (data['rotate'] - data['rotate'].mean())/data['rotate'].std()\n",
    "data['norm_t'] = (data['translate'] - data['translate'].mean())/data['translate'].std()\n",
    "data['norm_s'] = (data['scale'] - data['scale'].mean())/data['scale'].std()\n",
    "\n",
    "# 2. summarize the three varaibles\n",
    "w_r, w_t, w_s = 1, 1, 1\n",
    "data['spatial'] = data['norm_r'] * w_r + data['norm_t'] * w_t + data['norm_s'] * w_s\n",
    "data.to_csv(data_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rating = pd.read_csv('photodraw_tracing_rating.csv')\n",
    "spatial_error = data['spatial']\n",
    "shape_error = data['post_tran']\n",
    "rater1 = rating['rater1']\n",
    "\n",
    "norm_spatial = (spatial_error - np.mean(spatial_error))/np.std(spatial_error)\n",
    "norm_shape = (shape_error - np.mean(shape_error))/np.std(shape_error)\n",
    "overall_error = norm_spatial + norm_shape\n",
    "\n",
    "spatial_cor = pearsonr(spatial_error, rater1)\n",
    "shape_cor = pearsonr(shape_error, rater1)\n",
    "overall_cor = pearsonr(overall_error, rater1)\n",
    "\n",
    "print 'NCC loss'\n",
    "print 'correlate human judgments with spatial errors: r = {}, p = {}'.format(spatial_cor[0], spatial_cor[1])\n",
    "print 'correlate human judgments with shape errors: r = {}, p = {}'.format(shape_cor[0], shape_cor[1]) \n",
    "print 'correlate human judgments with shape+spatial errors: r = {}, p = {}'.format(overall_cor[0], overall_cor[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['rater1'] = rater1\n",
    "data.to_csv('photodraw_summary_{}.csv'.format(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare different loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "xlim = (-1,0)\n",
    "ylim = (0, 0.08)\n",
    "\n",
    "ncc = pd.read_csv('photodraw_tracing_ncc.csv')\n",
    "mse = pd.read_csv('photodraw_tracing_mse.csv')\n",
    "\n",
    "ncc_shape, ncc_spatial, ncc_overall = [], [], []\n",
    "mse_shape, mse_spatial, mse_overall = [], [], []\n",
    "\n",
    "for s in all_sessions:\n",
    "    current_ncc = ncc.loc[(ncc['session_id'] == s)]\n",
    "    \n",
    "    for index, draw in current_ncc.iterrows():\n",
    "        ncc_shape.append(draw['post_tran'])\n",
    "        ncc_spatial.append(draw['spatial'])\n",
    "        ncc_overall.append(draw['post_tran'] + draw['spatial'])\n",
    "        \n",
    "        current_mse = mse.loc[(mse['session_id'] == s) & (mse['tracing_item'] == draw['tracing_item'])]\n",
    "        mse_shape.append(current_mse['post_tran'].item())\n",
    "        mse_spatial.append(current_mse['spatial'].item())\n",
    "        mse_overall.append(current_mse['post_tran'].item() + current_mse['spatial'].item())\n",
    "\n",
    "\n",
    "plt.figure(figsize=(16,5))\n",
    "plt.subplot(1,2,1)\n",
    "h = plt.scatter(ncc_shape, mse_shape)\n",
    "plt.ylabel('MSE Shape Error')\n",
    "plt.xlabel('NCC Shape Error')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "h = plt.scatter(ncc_spatial, mse_spatial)\n",
    "plt.ylabel('MSE Spatial Error')\n",
    "plt.xlabel('NCC Spatial Error')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape_loss_cor = pearsonr(ncc_shape, mse_shape)\n",
    "spatial_loss_cor = pearsonr(ncc_spatial, mse_spatial)\n",
    "overall_loss_cor = pearsonr(ncc_overall, mse_overall)\n",
    "\n",
    "print \"NCC loss vs. MSE loss Pearson'r Correlation\"\n",
    "print 'correlate NCC shape error with MSE shape errors: r = {}, p = {}'.format(shape_loss_cor[0], shape_loss_cor[1])\n",
    "print 'correlate NCC spatial error with MSE spatial errors: r = {}, p = {}'.format(spatial_loss_cor[0], spatial_loss_cor[1])\n",
    "print 'correlate NCC overall error with MSE overall errors: r = {}, p = {}'.format(overall_loss_cor[0], overall_loss_cor[1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
