{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division\n",
    "\n",
    "import os\n",
    "import urllib, cStringIO\n",
    "\n",
    "import pymongo as pm\n",
    "\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "\n",
    "from PIL import Image\n",
    "import base64\n",
    "import sys\n",
    "\n",
    "import matplotlib\n",
    "from matplotlib import pylab, mlab, pyplot\n",
    "%matplotlib inline\n",
    "from IPython.core.pylabtools import figsize, getfigs\n",
    "plt = pyplot\n",
    "import seaborn as sns\n",
    "sns.set_context('talk')\n",
    "sns.set_style('darkgrid')\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", message=\"numpy.dtype size changed\")\n",
    "warnings.filterwarnings(\"ignore\", message=\"numpy.ufunc size changed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set vars \n",
    "auth = pd.read_csv('auth.txt', header = None) # this auth.txt file contains the password for the sketchloop user\n",
    "pswd = auth.values[0][0]\n",
    "user = 'sketchloop'\n",
    "host = 'rxdhawkins.me' ## cocolab ip address\n",
    "\n",
    "# have to fix this to be able to analyze from local\n",
    "import pymongo as pm\n",
    "conn = pm.MongoClient('mongodb://sketchloop:' + pswd + '@127.0.0.1')\n",
    "db = conn['kiddraw']\n",
    "coll = db['tracing_eval']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing\n",
    "#### Basic Information about mturk ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#iteration_names = ['pilot0', 'pilot1']\n",
    "iteration_names = ['pilot0']\n",
    "for t in iteration_names:\n",
    "    data_t = coll.find({'$and':[{'iterationName':t},{'workerId':{'$exists':True}}]}).sort('startTrialTime').sort('workerId')\n",
    "    print 'Iteration {} has {} ratings'.format(t, data_t.count())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sessions = coll.distinct('workerId') \n",
    "print \"Currently, {} mturkers have finished the game\".format(len(all_sessions)-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "expected = []\n",
    "finished = []\n",
    "repeated = 0\n",
    "more_catch = 0\n",
    "\n",
    "for s in all_sessions:\n",
    "    if s == '':\n",
    "        continue\n",
    "    finished_trials = coll.find({ \"workerId\": s})\n",
    "    default_trials = coll.find({\"workerId\": s,'category':'catch'})\n",
    "    \n",
    "    if finished_trials.count() == 105 and default_trials.count() == 5:\n",
    "        expected.append(finished_trials)\n",
    "    if finished_trials.count() == 105:\n",
    "        finished.append(finished_trials)\n",
    "    if finished_trials.count() >105:\n",
    "        iterName = list(finished_trials)[0]['iterationName']\n",
    "        print \"Worker {} in iteration {} has finished {} trials. {} trials are catch trials\".format(s, iterName, finished_trials.count(), default_trials.count())\n",
    "        repeated += 1\n",
    "    if default_trials.count() > 5:\n",
    "        more_catch += 1\n",
    "\n",
    "print \"\\nAmong {} mturkers, {} finished the survey. \".format(len(all_sessions)-1, len(finished))\n",
    "print \"Among {} mturkers who finished the game, {} was completed in a normal condition (105 trials, 5 catch)\".format(len(finished), len(expected))\n",
    "print \"{} mturkers finished more that 105 trials.\".format(repeated)\n",
    "print \"{} mturkers encountered more than 5 catch/default trials\".format(more_catch)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating raters by the following criterions and exclude raters who gave random responses:\n",
    "    1. 80% Answers of the catch trial are consistent and the average is larger than 2 ï¼ˆon a 0-4 scale)\n",
    "    2. There are no more than 20 continuous trials that have the same rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    all_sessions.remove('')\n",
    "except:\n",
    "    print \" '' is already removed\"\n",
    "    \n",
    "excluded_workerId = ['', ] # '' is 'no workerId'\n",
    "valid_ratings = []\n",
    "\n",
    "exc_incatch = []\n",
    "exc_2catch = []\n",
    "exc_20 = []\n",
    "\n",
    "tolerance = 0.8\n",
    "threshold = 2\n",
    "\n",
    "for s in all_sessions: \n",
    "    strials = coll.find({'workerId':s})\n",
    "    \n",
    "    # if no ratings, exclude the current rater\n",
    "    if strials.count() == 0:\n",
    "        excluded_workerId.append(s)\n",
    "        continue\n",
    "    \n",
    "    if list(strials)[0]['iterationName'] not in iteration_names:\n",
    "        excluded_workerId.append(s)\n",
    "        continue\n",
    "        \n",
    "    # if answers of catch trials are inconsistent, exclude the rater\n",
    "    catch = coll.find({'workerId':s, 'category':'catch'})\n",
    "    if catch.count() == 0: # no catch trials = no ratings at all. The first trial is the catch trial\n",
    "        excluded_workerId.append(s)\n",
    "        continue\n",
    "        \n",
    "    catch_answer = []\n",
    "    for t in catch:\n",
    "        catch_answer.append(int(t['button_pressed']))\n",
    "    \n",
    "    catch_answer = np.array(catch_answer)\n",
    "    \n",
    "    # check if all answers are larger than the threshold\n",
    "    if len(np.where(catch_answer>threshold)[0]) != len(catch_answer): \n",
    "        excluded_workerId.append(s)\n",
    "        exc_2catch.append(s)\n",
    "        continue\n",
    "    \n",
    "    # check if tolerance% of answers are the same number\n",
    "    counts = np.max(np.bincount(catch_answer))\n",
    "    if counts < len(catch_answer) * tolerance:\n",
    "        excluded_workerId.append(s)\n",
    "        exc_incatch.append(s)\n",
    "        continue\n",
    "    \n",
    "    # if more than 20 continuous trials are all the same, exclude the rater\n",
    "    # 1. get all non-catch answers\n",
    "    trials = coll.find({'workerId':s, 'category':{'$not':{'$eq':'catch'}}}).sort('trial_index')\n",
    "    if trials.count() == 0:\n",
    "        excluded_workerId.append(s)\n",
    "        continue\n",
    "    \n",
    "    nc_answer = []\n",
    "    current_rating = pd.DataFrame(list(trials))\n",
    "    nc_answer = current_rating['button_pressed']\n",
    "    \n",
    "    # 2. check for repetitions\n",
    "    rep = nc_answer[0]\n",
    "    rep_times = 0\n",
    "\n",
    "    for v in nc_answer[1:]:\n",
    "        if v == rep:\n",
    "            rep_times+= 1\n",
    "            if rep_times == 20: \n",
    "                print 'catch'\n",
    "                break\n",
    "        else:\n",
    "            rep = v\n",
    "            rep_times = 0\n",
    "    \n",
    "    if rep_times == 20:\n",
    "        excluded_workerId.append(s)\n",
    "        exc_20.append(s)\n",
    "        continue\n",
    "            \n",
    "    valid_ratings.append(current_rating)\n",
    "    \n",
    "print \"Excluded workerIds are {}\".format(excluded_workerId)\n",
    "print \"{} participants has inconsistent catch trial answers\".format(len(exc_incatch))\n",
    "print \"{} participants gave a comparatively low rating (0, 1, 2) to one or more catch trials\".format(len(exc_2catch))\n",
    "print \"{} participants has the same ratings for more than 20 continuous trials\".format(len(exc_20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write valid responses to a csv file\n",
    "all_norm = pd.concat(valid_ratings)\n",
    "all_norm.to_csv('valid_rating2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered = [s for s in all_sessions if s not in excluded_workerId]\n",
    "print 'We have {} participants in total. After the filtering process, there are {} participants remaining'.format(len(all_sessions), len(filtered))\n",
    "\n",
    "num_ratings = coll.find({'workerId':{'$nin': excluded_workerId}, 'category':{'$not':{'$eq':'catch'}}})\n",
    "print \"We have {} ratings from {} valid raters on {} children's tracings.\".format(num_ratings.count(), len(filtered), len(num_ratings.distinct('session_id')))\n",
    "\n",
    "unique_tracings = num_ratings.distinct('session_id')\n",
    "print \" {} mturkers has rated {} tracings\".format(len(filtered), len(unique_tracings))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine Human Rating Results with Image Registration Model Results\n",
    "For all tracings in the museumstation, the csv file $model$_$result$ contains model outputs. The model output consists of shape error and spatial error for each tracing image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read relevant files\n",
    "model_result = 'museumstation_tracing_ncc.csv'\n",
    "rating_result = 'valid_rating2.csv'\n",
    "data = pd.read_csv(model_result)\n",
    "all_norm = pd.read_csv(rating_result)\n",
    "all_norm = all_norm.drop(all_norm[all_norm['iterationName'] == 'testing2'].index)\n",
    "all_norm = all_norm.drop(all_norm[all_norm['session_id'].str.contains('CDM_photodraw')].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the model result\n",
    "# 1. normalize rotation, translation, and scaling\n",
    "data['norm_r'] = (data['rotate'] - data['rotate'].mean())/data['rotate'].std()\n",
    "data['norm_t'] = (data['translate'] - data['translate'].mean())/data['translate'].std()\n",
    "data['norm_s'] = (data['scale'] - data['scale'].mean())/data['scale'].std()\n",
    "\n",
    "# 2. summarize the three varaibles\n",
    "w_r, w_t, w_s = 1, 1, 1\n",
    "data['spatial'] = data['norm_r'] * w_r + data['norm_t'] * w_t + data['norm_s'] * w_s\n",
    "\n",
    "try:\n",
    "    data = data.drop([\"Unnamed: 0\", \"Unnamed: 0.1\"], axis=1)\n",
    "except:\n",
    "    print \"Already dropped\"\n",
    "\n",
    "data.to_csv(model_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norating = data.loc[data['human_norm_rating'].isnull()].index\n",
    "data.loc[norating, 'human_norm_rating'] = -10.0\n",
    "data.loc[norating, 'human_rating'] = -10.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data['button_pressed'] = -10\n",
    "new_data = []\n",
    "drop_index = []\n",
    "\n",
    "for di, d in data.iterrows():\n",
    "#     if di>50:\n",
    "#         break\n",
    "    human_rating = all_norm[(all_norm['session_id'] == d['session_id']) & (all_norm['category'] == d['category'])]\n",
    "    if human_rating.shape[0]!=0: # if the current item is rated and there exists at least one rating\n",
    "        # duplicate the same row for several times\n",
    "        dnew = pd.DataFrame(np.tile(d.values, (human_rating.shape[0],1)))\n",
    "        dnew.columns = data.columns\n",
    "        ratings = list(human_rating['button_pressed'].astype(int))\n",
    "        \n",
    "        # fill in the 'button_pressed' value\n",
    "        for hi, h in dnew.iterrows():\n",
    "            dnew.loc[hi, 'button_pressed'] = ratings[hi]\n",
    "        \n",
    "        new_data.append(dnew)\n",
    "        drop_index.append(di)\n",
    "        all_norm = all_norm.drop(human_rating.index)\n",
    "\n",
    "print len(drop_index)\n",
    "data = data.drop(drop_index)\n",
    "new_data.append(data)\n",
    "new_data = pd.concat(new_data)\n",
    "\n",
    "try:\n",
    "    new_data = new_data.drop('Unnamed: 0', axis=1)\n",
    "except:\n",
    "    print 'already dropped'  \n",
    "\n",
    "new_data = new_data.reset_index()\n",
    "try:\n",
    "    new_data = new_data.drop('index', axis=1)\n",
    "except:\n",
    "    print 'already dropped'\n",
    "    \n",
    "new_data.to_csv('tracing_ordinal_data.csv')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(pd.unique(data[['session_id', 'category']].values.ravel()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(pd.unique(new_data[['session_id','category']].values.ravel()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop_duplicates(subset=['session_id', 'category'], keep=\"last\")\n",
    "data.drop('Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
