{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division\n",
    "\n",
    "import os\n",
    "import urllib, cStringIO\n",
    "\n",
    "import pymongo as pm\n",
    "\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "\n",
    "from PIL import Image\n",
    "import base64\n",
    "import sys\n",
    "\n",
    "import matplotlib\n",
    "from matplotlib import pylab, mlab, pyplot\n",
    "%matplotlib inline\n",
    "from IPython.core.pylabtools import figsize, getfigs\n",
    "plt = pyplot\n",
    "import seaborn as sns\n",
    "sns.set_context('talk')\n",
    "sns.set_style('darkgrid')\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", message=\"numpy.dtype size changed\")\n",
    "warnings.filterwarnings(\"ignore\", message=\"numpy.ufunc size changed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set vars \n",
    "auth = pd.read_csv('auth.txt', header = None) # this auth.txt file contains the password for the sketchloop user\n",
    "pswd = auth.values[0][0]\n",
    "user = 'sketchloop'\n",
    "host = 'rxdhawkins.me' ## cocolab ip address\n",
    "\n",
    "# have to fix this to be able to analyze from local\n",
    "import pymongo as pm\n",
    "conn = pm.MongoClient('mongodb://sketchloop:' + pswd + '@127.0.0.1')\n",
    "db = conn['kiddraw']\n",
    "coll = db['tracing_eval']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing\n",
    "#### Basic Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iteration_names = ['pilot0', 'pilot1']\n",
    "for t in iteration_names:\n",
    "    data_t = coll.find({'$and':[{'iterationName':t},{'workerId':{'$exists':True}}]}).sort('startTrialTime').sort('workerId')\n",
    "    print 'Iteration {} has {} number of ratings'.format(t, data_t.count())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sessions = coll.distinct('workerId') \n",
    "print \"Currently, {} mturkers have finished the game\".format(len(all_sessions)-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "expected = []\n",
    "finished = []\n",
    "repeated = 0\n",
    "more_catch = 0\n",
    "\n",
    "for s in all_sessions:\n",
    "    if s == '':\n",
    "        continue\n",
    "    finished_trials = coll.find({ \"workerId\": s})\n",
    "    default_trials = coll.find({\"workerId\": s,'category':'catch'})\n",
    "    \n",
    "    if finished_trials.count() == 105 and default_trials.count() == 5:\n",
    "        expected.append(finished_trials)\n",
    "    if finished_trials.count() == 105:\n",
    "        finished.append(finished_trials)\n",
    "    if finished_trials.count() >105:\n",
    "        iterName = list(finished_trials)[0]['iterationName']\n",
    "        print \"Worker {} in iteration {} has finished {} trials. {} trials are catch trials\".format(s, iterName, finished_trials.count(), default_trials.count())\n",
    "        repeated += 1\n",
    "    if default_trials.count() > 5:\n",
    "        more_catch += 1\n",
    "\n",
    "print \"\\nAmong {} mturkers, {} finished the survey. \".format(len(all_sessions)-1, len(finished))\n",
    "print \"Among {} mturkers who finished the game, {} was completed in a normal condition (105 trials, 5 catch)\".format(len(finished), len(expected))\n",
    "print \"{} mturkers finished more that 105 trials.\".format(repeated)\n",
    "print \"{} mturkers encountered more than 5 catch/default trials\".format(more_catch)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = coll.find({'workerId':'A33VGSEJ44ORMF'})\n",
    "r = pd.DataFrame(list(r))\n",
    "r.to_csv('check.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating raters by the following criterions and exclude raters who gave random responses:\n",
    "    1. Answers of the catch trial are consistent and the average is larger than 2\n",
    "    2. There are no more than 20 continuous trials that have the same rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    all_sessions.remove('')\n",
    "except:\n",
    "    print \" '' is already removed\"\n",
    "    \n",
    "excluded_workerId = ['', ] # '' is 'no workerId'\n",
    "valid_ratings = []\n",
    "\n",
    "exc_incatch = []\n",
    "exc_2catch = []\n",
    "exc_20 = []\n",
    "\n",
    "tolerance = 0.8\n",
    "threshold = 2\n",
    "\n",
    "for s in all_sessions:     \n",
    "    strials = coll.find({'workerId':s})\n",
    "    \n",
    "    # if no ratings, exclude the current rater\n",
    "    if strials.count() == 0:\n",
    "        excluded_workerId.append(s)\n",
    "        continue\n",
    "    \n",
    "    if list(strials)[0]['iterationName'] not in iteration_names:\n",
    "        excluded_workerId.append(s)\n",
    "        continue\n",
    "        \n",
    "    # if answers of catch trials are inconsistent, exclude the rater\n",
    "    catch = coll.find({'workerId':s, 'category':'catch'})\n",
    "    if catch.count() == 0: # no catch trials = no ratings at all. The first trial is the catch trial\n",
    "        excluded_workerId.append(s)\n",
    "        continue\n",
    "        \n",
    "    catch_answer = []\n",
    "    for t in catch:\n",
    "        catch_answer.append(int(t['button_pressed']))\n",
    "    \n",
    "    catch_answer = np.array(catch_answer)\n",
    "    \n",
    "    # check if all answers are larger than the threshold\n",
    "    if len(np.where(catch_answer>threshold)[0]) != len(catch_answer): \n",
    "        excluded_workerId.append(s)\n",
    "        exc_2catch.append(s)\n",
    "        continue\n",
    "    \n",
    "    # check if tolerance% of answers are the same number\n",
    "    counts = np.max(np.bincount(catch_answer))\n",
    "    if counts < len(catch_answer) * tolerance:\n",
    "        excluded_workerId.append(s)\n",
    "        exc_incatch.append(s)\n",
    "        continue\n",
    "    \n",
    "    # if more than 20 continuous trials are all the same, exclude the rater\n",
    "    # 1. get all non-catch answers\n",
    "    trials = coll.find({'workerId':s, 'category':{'$not':{'$eq':'catch'}}}).sort('trial_index')\n",
    "    if trials.count() == 0:\n",
    "        excluded_workerId.append(s)\n",
    "        continue\n",
    "    \n",
    "    nc_answer = []\n",
    "    current_rating = pd.DataFrame(list(trials))\n",
    "    nc_answer = current_rating['button_pressed']\n",
    "    \n",
    "    # 2. check for repetitions\n",
    "    rep = nc_answer[0]\n",
    "    rep_times = 0\n",
    "\n",
    "    for v in nc_answer[1:]:\n",
    "        if v == rep:\n",
    "            rep_times+= 1\n",
    "            if rep_times == 20: \n",
    "                print 'catch'\n",
    "                break\n",
    "        else:\n",
    "            rep = v\n",
    "            rep_times = 0\n",
    "    \n",
    "    if rep_times == 20:\n",
    "        excluded_workerId.append(s)\n",
    "        exc_20.append(s)\n",
    "        continue\n",
    "            \n",
    "    valid_ratings.append(current_rating)\n",
    "    \n",
    "print \"Excluded workerIds are {}\".format(excluded_workerId)\n",
    "print \"{} participants has inconsistent catch trial answers\".format(len(exc_incatch))\n",
    "print \"{} participants gave a comparatively low rating (0, 1, 2) to one or more catch trials\".format(len(exc_2catch))\n",
    "print \"{} participants has the same ratings for more than 20 continuous trials\".format(len(exc_20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_norm = pd.concat(valid_ratings)\n",
    "all_norm.to_csv('valid_rating.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered = [s for s in all_sessions if s not in excluded_workerId]\n",
    "print 'We have {} participants in total. After the filtering process, there are {} participants remaining'.format(len(all_sessions), len(filtered))\n",
    "\n",
    "num_ratings = coll.find({'workerId':{'$nin': excluded_workerId}, 'category':{'$not':{'$eq':'catch'}}})\n",
    "print \"We have {} ratings from {} valid raters on {} children's tracings.\".format(num_ratings.count(), len(filtered), len(num_ratings.distinct('session_id')))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Age and Shape Trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw ratings\n",
    "categories = ['square', 'shape', 'circle']\n",
    "plt.figure(figsize=(18,5))\n",
    "plt.subplots_adjust(wspace=0.3)\n",
    "\n",
    "for ti, thiscat in enumerate(categories):\n",
    "    thissubset = coll.find({'$and': [{'iterationName':iterationName},{'workerId':{'$exists':True}}, {'category':thiscat}]})\n",
    "    \n",
    "    ages = np.arange(2,11)\n",
    "    cat_rating = []\n",
    "    for a in ages:\n",
    "        cat_rating.append([])\n",
    "\n",
    "    for rating in thissubset:\n",
    "        age = rating['image_url'].split('/')[-1].split('_')[0]\n",
    "        age_index = int(age[3:])-2\n",
    "        cat_rating[age_index].append(int(rating['button_pressed']))\n",
    "    \n",
    "    mean_cat = [np.average(cat) for cat in cat_rating]\n",
    "    \n",
    "    plt.subplot(1,3,ti+1)\n",
    "    y_pos = np.arange(len(ages))\n",
    "    h = plt.bar(y_pos, mean_cat)\n",
    "    plt.xticks(y_pos, ages)\n",
    "    plt.ylabel(thiscat +' average rating')\n",
    "    plt.xlabel('age')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "all_norm = norm_rating\n",
    "categories = ['square', 'shape', 'circle']\n",
    "plt.figure(figsize=(18,5))\n",
    "plt.subplots_adjust(wspace=0.3)\n",
    "\n",
    "for ti, thiscat in enumerate(categories):\n",
    "    ages = []\n",
    "    cat_rating = []\n",
    "    thissubset = all_norm.loc[all_norm['category'] == thiscat]\n",
    "\n",
    "    for ri, rating in thissubset.iterrows():\n",
    "        age = rating['image_url'].split('/')[-1].split('_')[0]\n",
    "        ages.append(int(age[3:]))\n",
    "        cat_rating.append(rating['norm_rating'])\n",
    "    \n",
    "    plt.subplot(1,3,ti+1)\n",
    "    h = plt.scatter(ages, cat_rating)\n",
    "    plt.ylabel(thiscat +' human rating')\n",
    "    plt.xlabel('age')\n",
    "\n",
    "    \n",
    "for ti, thiscat in enumerate(categories):\n",
    "    ages = np.arange(2,11)\n",
    "    cat_rating = []\n",
    "    for a in ages:\n",
    "        cat_rating.append([])\n",
    "    \n",
    "    thissubset = all_norm.loc[all_norm['category'] == thiscat]\n",
    "\n",
    "    for ri, rating in thissubset.iterrows():\n",
    "        age = rating['image_url'].split('/')[-1].split('_')[0]\n",
    "        age_index = int(age[3:])-2\n",
    "        cat_rating[age_index].append(rating['norm_rating'])\n",
    "    \n",
    "    for ci, cat in enumerate(cat_rating):\n",
    "        print \"There are {} {} tracings from children at age {}\".format(len(cat), thiscat, ci+2)\n",
    "    \n",
    "    mean_cat = [np.average(cat) for cat in cat_rating]\n",
    "    \n",
    "    plt.subplot(1,3,ti+1)\n",
    "    y_pos = np.arange(len(ages))\n",
    "    h = plt.plot(ages, mean_cat, 'ro')\n",
    "    plt.ylabel(thiscat +' normalized rating')\n",
    "    plt.xlabel('age')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_output = 'museumstation_tracing_ncc.csv'\n",
    "data = pd.read_csv(data_output)\n",
    "\n",
    "# data_output = 'kiddraw_tracing_ncc.csv'\n",
    "data['norm_r'] = (data['rotate'] - data['rotate'].mean())/data['rotate'].std()\n",
    "data['norm_t'] = (data['translate'] - data['translate'].mean())/data['translate'].std()\n",
    "data['norm_s'] = (data['scale'] - data['scale'].mean())/data['scale'].std()\n",
    "\n",
    "# 2. summarize the three varaibles\n",
    "w_r, w_t, w_s = 1, 1, 1\n",
    "data['spatial'] = data['norm_r'] * w_r + data['norm_t'] * w_t + data['norm_s'] * w_s\n",
    "try:\n",
    "    data = data.drop([\"Unnamed: 0\", \"Unnamed: 0.1\"], axis=1)\n",
    "except:\n",
    "    print \"Already dropped\"\n",
    "\n",
    "data.to_csv(data_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_output = 'museumstation_tracing_ncc.csv'\n",
    "try:\n",
    "    data = data.drop(\"Unnamed: 0\", axis=1)\n",
    "except:\n",
    "    print \"Already dropped\"\n",
    "data.to_csv(data_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norating = data.loc[data['human_norm_rating'].isnull()].index\n",
    "data.loc[norating, 'human_norm_rating'] = -10.0\n",
    "data.loc[norating, 'human_rating'] = -10.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(data_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_norm[\"category\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_norm = pd.read_csv('valid_rating.csv')\n",
    "all_norm = all_norm.drop(all_norm[all_norm['iterationName'] == 'testing2'].index)\n",
    "all_norm = all_norm.drop(all_norm[all_norm['session_id'].str.contains('CDM_photodraw')].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print all_norm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_output = 'museumstation_tracing_eval.csv'\n",
    "data = pd.read_csv(data_output)\n",
    "\n",
    "data['button_pressed'] = -10\n",
    "new_data = []\n",
    "drop_index = []\n",
    "\n",
    "for di, d in data.iterrows():\n",
    "#     if di>50:\n",
    "#         break\n",
    "    human_rating = all_norm[(all_norm['session_id'] == d['session_id']) & (all_norm['category'] == d['category'])]\n",
    "    if human_rating.shape[0]!=0: # if the current item is rated and there exists at least one rating\n",
    "        # duplicate the same row for several times\n",
    "        dnew = pd.DataFrame(np.tile(d.values, (human_rating.shape[0],1)))\n",
    "        dnew.columns = data.columns\n",
    "        ratings = list(human_rating['button_pressed'].astype(int))\n",
    "        \n",
    "        # fill in the 'button_pressed' value\n",
    "        for hi, h in dnew.iterrows():\n",
    "            dnew.loc[hi, 'button_pressed'] = ratings[hi]\n",
    "        \n",
    "        new_data.append(dnew)\n",
    "        drop_index.append(di)\n",
    "        all_norm = all_norm.drop(human_rating.index)\n",
    "\n",
    "print len(drop_index)\n",
    "data = data.drop(drop_index)\n",
    "new_data.append(data)\n",
    "new_data = pd.concat(new_data)\n",
    "\n",
    "try:\n",
    "    new_data = new_data.drop('Unnamed: 0', axis=1)\n",
    "except:\n",
    "    print 'already dropped'  \n",
    "\n",
    "new_data = new_data.reset_index()\n",
    "try:\n",
    "    new_data = new_data.drop('index', axis=1)\n",
    "except:\n",
    "    print 'already dropped'\n",
    "    \n",
    "new_data.to_csv('tracing_ordinal_data.csv')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(pd.unique(data[['session_id', 'category']].values.ravel()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
