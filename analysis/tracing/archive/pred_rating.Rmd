---
title: "Correlation between Tracing Analysis and Human rating"
output: html_document
---

```{r}
library(MASS)
library(lme4)
library(tidyverse)
library(DescTools)
library(broom)
```

## Summary
Three types of Loss: MSE, F1, NCC(normalized cross-correlation)

Human Rating Scale: 0 (completely off) to 4 (perfectly aligned)

Best Result: NCC Loss

Correlation between NCC shape+spatial Error and Human Rating: r = - 0.81, p < 0.01

Ordinal Regression: NC Loss has the lowest deviation from human rating (lowest residual deviance and AIC)

## MSE Loss

#### Import data
```{r}
rater_data <- read.csv('./photodraw_summary_mse.csv')
rater_data$post_tran = scale(rater_data$post_tran)
rater_data$spatial = scale(rater_data$spatial)
rater_data$overall = rater_data$spatial + rater_data$post_tran
```

#### Visualize shape error and human judgments
```{r}
ggplot(rater_data, aes(post_tran, rater1, color=tracing_item)) +
  geom_point(size=3) +
  theme_bw() + 
  xlab("shape error") +
  ylab("human judgment") +
  ggtitle('Shape Error vs. Human judgment')
```

#### Visualize spatial error and human judgments
```{r}
ggplot(rater_data, aes(spatial, rater1, color=tracing_item)) +
  geom_point(size=3) +
  theme_bw() + 
  xlab("spatial error") +
  ylab("human judgment") +
  ggtitle('Spatial Error vs. Human judgment')
```

#### Visualize shape+spatial error and human judgments
```{r}
ggplot(rater_data, aes(overall, rater1, color=tracing_item)) +
  geom_point(size=3) +
  theme_bw() + 
  xlab("shape+spatial error") +
  ylab("human judgment") +
  ggtitle('Shape+Spatial Error vs. Human judgment')
```

#### Corrleation of human rating with MSE Loss: 
Shape Error and Human Rating: r = - 0.65, p < 0.01

Spatial Error and Human Rating: r = - 0.58, p < 0.01

Shape+Spatial Error and Human Rating: r = - 0.76, p < 0.01

```{r}
cor.test(rater_data$post_tran, rater_data$rater1)
```
```{r}
cor.test(rater_data$spatial, rater_data$rater1)
```
```{r}
cor.test(rater_data$overall, rater_data$rater1)
```
```{r}
worse_score = rater_data[rater_data[, "rater1"] <2,]
cor(worse_score$overall, worse_score$rater1)
cor(worse_score$spatial, worse_score$rater1)
cor(worse_score$post_tran, worse_score$rater1)

worse_score = rater_data[rater_data[, "rater1"] >1,]
cor(worse_score$overall, worse_score$rater1)
cor(worse_score$spatial, worse_score$rater1)
cor(worse_score$post_tran, worse_score$rater1)
```

#### Ordinal logistic model
```{r}
rater_data$rater1 <- factor(rater_data$rater1, levels = c("0", "1", "2", "3", "4"), ordered=TRUE)
ord_m <- polr(rater1 ~ spatial + post_tran, rater_data, Hess=TRUE)
summary(ord_m)

ctable <- coef(summary(ord_m))
p <- pnorm(abs(ctable[, "t value"]), lower.tail = FALSE) * 2
(ctable <- cbind(ctable, "p value" = p))

print('exp(coefficient of spatial and post_tran)')
exp(coef(ord_m))

print('pseudo R2')
PseudoR2(ord_m, 'all')
```

## F1 Loss

#### Import data
```{r}
rater_data <- read.csv('./photodraw_summary_f1.csv')
rater_data$post_tran = scale(rater_data$post_tran)
rater_data$spatial = scale(rater_data$spatial)
rater_data$overall = rater_data$spatial + rater_data$post_tran
```

#### Visualize shape error and human judgments
```{r}
ggplot(rater_data, aes(post_tran, rater1, color=tracing_item)) +
  geom_point(size=3) +
  theme_bw() + 
  xlab("shape error") +
  ylab("human judgment") +
  ggtitle('Shape Error vs. Human judgment')
```

#### Visualize spatial error and human judgments
```{r}
ggplot(rater_data, aes(spatial, rater1, color=tracing_item)) +
  geom_point(size=3) +
  theme_bw() + 
  xlab("spatial error") +
  ylab("human judgment") +
  ggtitle('Spatial Error vs. Human judgment')
```

#### Visualize shape+spatial error and human judgments
```{r}
ggplot(rater_data, aes(overall, rater1, color=tracing_item)) +
  geom_point(size=3) +
  theme_bw() + 
  xlab("shape+spatial error") +
  ylab("human judgment") +
  ggtitle('Shape+Spatial Error vs. Human judgment')
```

#### Corrleation of human rating with F1 Loss: 
Shape Error and Human Rating: r = - 0.55, p < 0.01

Spatial Error and Human Rating: r = - 0.56, p < 0.01

Shape+Spatial Error and Human Rating: r = - 0.71, p < 0.01

```{r}
cor.test(rater_data$post_tran, rater_data$rater1)
```
```{r}
cor.test(rater_data$spatial, rater_data$rater1)
```
```{r}
cor.test(rater_data$overall, rater_data$rater1)
```

#### Ordinal logistic model
```{r}
rater_data$rater1 <- factor(rater_data$rater1, levels = c("0", "1", "2", "3", "4"), ordered=TRUE)
ord_m <- polr(rater1 ~ spatial + post_tran, rater_data, Hess=TRUE)
summary(ord_m)
ctable <- coef(summary(ord_m))
p <- pnorm(abs(ctable[, "t value"]), lower.tail = FALSE) * 2
(ctable <- cbind(ctable, "p value" = p))

print('exp(coefficient of spatial and post_tran)')
exp(coef(ord_m))

print('pseudo R2')
PseudoR2(ord_m, 'all')
```

### NCC Loss

For a reference and a drawing:

1. Multiply the value (0-1) at each pair of corresponding pixels and sum them up

2. Normalize the sum to mean=0, std=1

#### Import data
```{r}
rater_data <- read.csv('./photodraw_summary_ncc.csv')
rater_data$post_tran = scale(rater_data$post_tran)
rater_data$spatial = scale(rater_data$spatial)
rater_data$overall = rater_data$spatial + rater_data$post_tran
```

#### Visualize shape error and human judgments
```{r}
ggplot(rater_data, aes(post_tran, rater1, color=tracing_item)) +
  geom_point(size=3) +
  theme_bw() + 
  xlab("shape error") +
  ylab("human judgment") +
  ggtitle('Shape Error vs. Human judgment')
```

#### Visualize spatial error and human judgments
```{r}
ggplot(rater_data, aes(spatial, rater1, color=tracing_item)) +
  geom_point(size=3) +
  theme_bw() + 
  xlab("spatial error") +
  ylab("human judgment") +
  ggtitle('Spatial Error vs. Human judgment')
```

#### Visualize shape+spatial error and human judgments
```{r}
ggplot(rater_data, aes(overall, rater1, color=tracing_item)) +
  geom_point(size=3) +
  theme_bw() + 
  xlab("shape+spatial error") +
  ylab("human judgment") +
  ggtitle('Shape+Spatial Error vs. Human judgment')
```

#### Corrleation of human rating with NCC Loss: 
Shape Error and Human Rating: r = - 0.69, p < 0.01

Spatial Error and Human Rating: r = - 0.63, p < 0.01

Shape+Spatial Error and Human Rating: r = - 0.81, p < 0.01

```{r}
cor.test(rater_data$post_tran, rater_data$rater1)
```
```{r}
cor.test(rater_data$spatial, rater_data$rater1)
```
```{r}
cor.test(rater_data$overall, rater_data$rater1)
```

#### Ordinal logisitc model
```{r}
rater_data$rater1 <- factor(rater_data$rater1, levels = c("0", "1", "2", "3", "4"), ordered=TRUE)
ord_m <- polr(rater1 ~ spatial + post_tran, rater_data, Hess=TRUE)
summary(ord_m)
ctable <- coef(summary(ord_m))
p <- pnorm(abs(ctable[, "t value"]), lower.tail = FALSE) * 2
(ctable <- cbind(ctable, "p value" = p))

print('exp(coefficient of spatial and post_tran)')
exp(coef(ord_m))

print('pseudo R2')
PseudoR2(ord_m, 'all')
```

## Comparison
### Correlation
#### Shape
- MSE: r = - 0.65, p < 0.01
- F1: r = - 0.55, p < 0.01
- NCC: r = - 0.69, p < 0.01

#### Spatial
- MSE: r = - 0.58, p < 0.01
- F1: r = - 0.56, p < 0.01
- NCC: r = - 0.63, p < 0.01

#### Overall
- MSE: r = - 0.76, p < 0.01
- F1: r = - 0.71, p < 0.01
- NCC: r = - 0.81, p < 0.01

### Ordinal Regression
#### MSE: 
- Residual Deviance: 271.5021 
- AIC: 283.5021 
  
#### F1: 
- Residual Deviance: 301.668 
- AIC: 313.668

#### NCC: 
  - Residual Deviance: 243.3339 
  - AIC: 255.3339 
