{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import os\n",
    "import urllib, cStringIO\n",
    "import pymongo as pm ## first establish ssh tunnel to server where database is running\n",
    "import base64\n",
    "import numpy as np\n",
    "from numpy import *\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import base64\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "from matplotlib import pylab, mlab, pyplot\n",
    "from IPython.core.pylabtools import figsize, getfigs\n",
    "plt = pyplot\n",
    "import seaborn as sns\n",
    "sns.set_context('poster')\n",
    "sns.set_style('white')\n",
    "from matplotlib.path import Path\n",
    "import matplotlib.patches as patches\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from svgpathtools import parse_path\n",
    "import svg_distance_helpers as rsh\n",
    "import svg_render_helpers as rrh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### directory and file hierarchy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory & file hierarchy\n",
    "analysis_dir = os.getcwd()\n",
    "tracing_ref_pixel = os.path.join(analysis_dir, 'tracing_ref_pixel')\n",
    "tracing_ref_svg = os.path.join(analysis_dir, 'tracing_ref_svg')\n",
    "data_dir = os.path.join(analysis_dir,\"trace_test\")\n",
    "\n",
    "canvas_side = 432 # image size\n",
    "rows, cols = canvas_side, canvas_side # the size of a given drawing image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tracing/Copying Error Calculation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # change names. only for testing purpose\n",
    "# for index, imgfile in enumerate(os.listdir(data_dir)):\n",
    "#     new_filename = 'test{:02}.png'.format(index)\n",
    "#     os.rename(os.path.join(data_dir,imgfile), os.path.join(data_dir,new_filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.listdir(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# reload(rsh)\n",
    "# # get tracings from the data folder\n",
    "# #for file in os.listdir(data_dir):\n",
    "\n",
    "# # read in tracing and reference files\n",
    "# fpath = os.path.join(data_dir, 'test01.png')\n",
    "# img_draw = cv2.imread(fpath)\n",
    "# img_draw = rsh.white_color_to_num(img_draw)\n",
    "\n",
    "# square_ref_file = os.path.join(tracing_ref_pixel, 'resize_square.png')\n",
    "# img_ref = cv2.imread(square_ref_file)\n",
    "# img_ref = rsh.black_color_to_num(img_ref)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### set up a toy case where the ref and trace are identical and simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "\n",
    "class LinearTransform(torch.nn.Module):\n",
    "    def __init__(self, size):\n",
    "        super(LinearTransform, self).__init__()\n",
    "        self.transform = torch.nn.Linear(size, size, bias=True)  # two in and two out\n",
    "        # init the model with the identity transformation matrix\n",
    "        self.transform.weight = torch.nn.Parameter(torch.eye(size))\n",
    "        self.transform.bias = torch.nn.Parameter(torch.zeros(size))\n",
    "\n",
    "    def forward(self, x):\n",
    "        y_pred = self.transform(x)\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 5x5 image where there is a horizontal bar in the second row\n",
    "img_ref = np.zeros((5,5))\n",
    "img_ref[1,1:5] = 1\n",
    "\n",
    "img_draw = np.zeros((5,5))\n",
    "img_draw[2,1:5] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "## get x_data and y_data in the appropriate format\n",
    "num_rows, num_cols = img_ref.shape[0], img_ref.shape[1]\n",
    "end_index_1d = num_rows * num_cols - 1 # the unique id of the last pixel in both ref and draw\n",
    "\n",
    "draw_pixels = rsh.find_black_pixels(img_draw) # a list of pixels that are black  2 x k\n",
    "x_data = Variable(torch.tensor(draw_pixels, dtype=torch.float, ))\n",
    "y_data = Variable(torch.tensor(img_ref, dtype=torch.float).view(-1)) # 1 x end_index_1d."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init model\n",
    "model = LinearTransform(2)  # weight 2 x 2   bias 1 x 2\n",
    "# set up optimizer\n",
    "lr = 0.01\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "# number of training steps\n",
    "num_train_steps = 5\n",
    "\n",
    "## print model params\n",
    "# list(model.parameters())[0].data.numpy()\n",
    "\n",
    "loss = torch.tensor(0.0, dtype=torch.float, requires_grad=True)\n",
    "\n",
    "# thresholding\n",
    "threshold = nn.Hardtanh(0, end_index_1d) # change everything smaller than 0 to 0 and larger than end_index to end_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ref_select tensor([ 0.,  0.,  0.,  0.]) True\n",
      "loss = -0.0 grad = None\n",
      "ref_select tensor([ 0.,  0.,  0.,  0.]) True\n",
      "loss = -0.0 grad = None\n",
      "ref_select tensor([ 0.,  0.,  0.,  0.]) True\n",
      "loss = -0.0 grad = None\n",
      "ref_select tensor([ 0.,  0.,  0.,  0.]) True\n",
      "loss = -0.0 grad = None\n",
      "ref_select tensor([ 0.,  0.,  0.,  0.]) True\n",
      "loss = -0.0 grad = None\n"
     ]
    }
   ],
   "source": [
    "for j,epoch in enumerate(range(num_train_steps)):\n",
    "    x_prime = model(x_data) # 2 x k\n",
    "    x_prime_1d = rsh.pixel_list_to_1d(x_prime, num_cols) # 1 x 2k\n",
    "#     print '{}'.format(x_prime)\n",
    "#     print '{}'.format(x_prime_1d)    \n",
    "    \n",
    "    # threshold image\n",
    "    cropped = threshold(x_prime_1d)\n",
    "#     print 'cropped {} {}'.format(cropped, cropped.requires_grad)\n",
    "        \n",
    "    # get indices of on pixels in thresholded image\n",
    "    cropped_index = threshold(x_prime_1d).type(torch.long).requires_grad_()\n",
    "#     print 'cropped_index {} {}'.format(cropped_index, cropped_index.requires_grad)\n",
    "    \n",
    "    # index selection\n",
    "    ref_select = torch.index_select(y_data, 0, cropped_index).requires_grad_() # get color values on img_ref with overlapping indices\n",
    "    print 'ref_select {} {}'.format(ref_select, ref_select.requires_grad)\n",
    "    loss = -1e3 * torch.mean(ref_select)  \n",
    "    \n",
    "    # Zero gradients, perform a backward pass,\n",
    "    # and update the weights.\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "#     print 'model params: weight = {}; bias = {}'.format(model.transform.weight, model.transform.bias)\n",
    "    print 'loss = {} grad = {}'.format(loss, loss.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(rsh)\n",
    "loss, final_draw, weights, bias = rsh.minimize_shape_error(img_ref, img_draw)\n",
    "print loss\n",
    "print weights\n",
    "print bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### preprocessing of tracing and visualization (if desired)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reallyRun = 1\n",
    "if reallyRun:\n",
    "    rsh.plot_shape(verts_list, codes_list, canvas_side)\n",
    "    #rsh.plot_stroke(verts_list[1], codes_list[1], canvas_side)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare human rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(os.listdir(data_dir))\n",
    "data.columns = ['image_id']\n",
    "data.to_csv(os.path.join(analysis_dir,'performance.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
