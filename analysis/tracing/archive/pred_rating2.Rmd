---
title: "Correlation between Tracing Analysis and Human rating"
output: html_document
---

```{r}
library(MASS)
library(lme4)
library(tidyverse)
library(cowplot)
library(DescTools)
```

## Summary
Three types of Shape Errors: MSE, F1, NCC(normalized cross-correlation)

Human Rating Scale: 0 (completely off) to 4 (perfectly aligned)

Best Result: NCC Loss

Correlation between NCC shape+spatial Error and Human Rating: r = - 0.81, p < 0.01

### Import data
```{r}
# MSE
rater_mse <- read.csv('./photodraw_summary_mse.csv')
rater_mse$post_tran = scale(rater_mse$post_tran)
rater_mse$spatial = scale(rater_mse$spatial)
rater_mse$overall = rater_mse$spatial + rater_mse$post_tran

# F1
rater_f1 <- read.csv('./photodraw_summary_f1.csv')
rater_f1$post_tran = scale(rater_f1$post_tran)
rater_f1$spatial = scale(rater_f1$spatial)
rater_f1$overall = rater_f1$spatial + rater_f1$post_tran

# NCC
rater_ncc <- read.csv('./photodraw_summary_ncc.csv')
rater_ncc$post_tran = scale(rater_ncc$post_tran)
rater_ncc$spatial = scale(rater_ncc$spatial)
rater_ncc$overall = rater_ncc$spatial + rater_ncc$post_tran
```


### Visualize shape/spatial error and human judgments
#### Shape Error
```{r}
ggplot(rater_mse, aes(post_tran, rater1, color=tracing_item)) +
  geom_point(size=3) +
  theme_bw() + 
  xlab("MSE shape error") +
  ylab("human judgment") +
  ggtitle('MSE Shape Error vs. Human judgment')

ggplot(rater_f1, aes(post_tran, rater1, color=tracing_item)) +
  geom_point(size=3) +
  theme_bw() + 
  xlab("F1 shape error") +
  ylab("human judgment") +
  ggtitle('F1 Shape Error vs. Human judgment')

ggplot(rater_ncc, aes(post_tran, rater1, color=tracing_item)) +
  geom_point(size=3) +
  theme_bw() + 
  xlab("NCC shape error") +
  ylab("human judgment") +
  ggtitle('NCC Shape Error vs. Human judgment')


```

#### Spatial Error

```{r}
ggplot(rater_mse, aes(spatial, rater1, color=tracing_item)) +
  geom_point(size=3) +
  theme_bw() + 
  xlab("MSE spatial error") +
  ylab("human judgment") +
  ggtitle('MSE Spatial Error vs. Human judgment')

ggplot(rater_f1, aes(spatial, rater1, color=tracing_item)) +
  geom_point(size=3) +
  theme_bw() + 
  xlab("F1 spatial error") +
  ylab("human judgment") +
  ggtitle('F1 Spatial Error vs. Human judgment')

ggplot(rater_ncc, aes(spatial, rater1, color=tracing_item)) +
  geom_point(size=3) +
  theme_bw() + 
  xlab("NCC spatial error") +
  ylab("human judgment") +
  ggtitle('NCC Spatial Error vs. Human judgment')

```

#### Shape+Spatial Error
```{r}
ggplot(rater_mse, aes(overall, rater1, color=tracing_item)) +
  geom_point(size=3) +
  theme_bw() + 
  xlab("MSE shape+spatial error") +
  ylab("human judgment") +
  ggtitle('MSE Shape+Spatial Error vs. Human judgment')

ggplot(rater_f1, aes(overall, rater1, color=tracing_item)) +
  geom_point(size=3) +
  theme_bw() + 
  xlab("F1 shape+spatial error") +
  ylab("human judgment") +
  ggtitle('F1 Shape+Spatial Error vs. Human judgment')

ggplot(rater_ncc, aes(overall, rater1, color=tracing_item)) +
  geom_point(size=3) +
  theme_bw() + 
  xlab("NCC shape+spatial error") +
  ylab("human judgment") +
  ggtitle('NCC Shape+Spatial Error vs. Human judgment')

```

### Corrleation of human rating with different Loss: 
#### MSE Loss
Shape Error and Human Rating: r = - 0.65, p < 0.01
Spatial Error and Human Rating: r = - 0.58, p < 0.01
Shape+Spatial Error and Human Rating: r = - 0.76, p < 0.01

#### F1 Loss: 
Shape Error and Human Rating: r = - 0.55, p < 0.01
Spatial Error and Human Rating: r = - 0.56, p < 0.01
Shape+Spatial Error and Human Rating: r = - 0.71, p < 0.01

#### NCC Loss:
Shape Error and Human Rating: r = - 0.69, p < 0.01
Spatial Error and Human Rating: r = - 0.63, p < 0.01
Shape+Spatial Error and Human Rating: r = - 0.81, p < 0.01

```{r}
cor.test(rater_mse$post_tran, rater_mse$rater1)
```
```{r}
cor.test(rater_mse$spatial, rater_mse$rater1)
```
```{r}
cor.test(rater_mse$overall, rater_mse$rater1)
```

```{r}
cor.test(rater_f1$post_tran, rater_f1$rater1)
```
```{r}
cor.test(rater_f1$spatial, rater_f1$rater1)
```
```{r}
cor.test(rater_f1$overall, rater_f1$rater1)
```

```{r}
cor.test(rater_ncc$post_tran, rater_ncc$rater1)
```
```{r}
cor.test(rater_ncc$spatial, rater_ncc$rater1)
```
```{r}
cor.test(rater_ncc$overall, rater_ncc$rater1)
```


### Ordinal logistic model: How would each loss predict human judgments?
#### MSE Loss
```{r}
rater_mse$rater1 <- factor(rater_mse$rater1, levels = c("0", "1", "2", "3", "4"), ordered=TRUE)
ord_m <- polr(rater1 ~ spatial + post_tran, rater_mse, Hess=TRUE)
summary(ord_m)
ctable <- coef(summary(ord_m))
p <- pnorm(abs(ctable[, "t value"]), lower.tail = FALSE) * 2
(ctable <- cbind(ctable, "p value" = p))

print('exp(coefficient of spatial and post_tran)')
exp(coef(ord_m))
print('pseudo R2')
PseudoR2(ord_m, 'all')
```

#### F1 Loss
```{r}
rater_f1$rater1 <- factor(rater_f1$rater1, levels = c("0", "1", "2", "3", "4"), ordered=TRUE)
ord_m <- polr(rater1 ~ spatial + post_tran, rater_f1, Hess=TRUE)
summary(ord_m)
ctable <- coef(summary(ord_m))
p <- pnorm(abs(ctable[, "t value"]), lower.tail = FALSE) * 2
(ctable <- cbind(ctable, "p value" = p))

print('exp(coefficient of spatial and post_tran)')
exp(coef(ord_m))
print('pseudo R2')
PseudoR2(ord_m, 'all')
```

#### NCC Loss
```{r}
rater_ncc$rater1 <- factor(rater_ncc$rater1, levels = c("0", "1", "2", "3", "4"), ordered=TRUE)
ord_m <- polr(rater1 ~ spatial + post_tran, rater_ncc, Hess=TRUE)
summary(ord_m)
ctable <- coef(summary(ord_m))
p <- pnorm(abs(ctable[, "t value"]), lower.tail = FALSE) * 2
(ctable <- cbind(ctable, "p value" = p))

print('exp(coefficient of spatial and post_tran)')
exp(coef(ord_m))
print('pseudo R2')
PseudoR2(ord_m, 'all')

```


