{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import sys\n",
    "import os\n",
    "import urllib, cStringIO\n",
    "import pymongo as pm ## first establish ssh tunnel to server where database is running\n",
    "import base64\n",
    "import numpy as np\n",
    "from numpy import *\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import base64\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "from matplotlib import pylab, mlab, pyplot\n",
    "from IPython.core.pylabtools import figsize, getfigs\n",
    "plt = pyplot\n",
    "import seaborn as sns\n",
    "sns.set_context('poster')\n",
    "sns.set_style('white')\n",
    "import pandas as pd\n",
    "from svgpathtools import parse_path\n",
    "import svg_distance_helpers as rsh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### File Hierarchy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# directory & file hierarchy\n",
    "analysis_dir = os.path.abspath('..')\n",
    "tracing_dir = os.path.join(analysis_dir,'tracing')\n",
    "data_dir = os.path.join(analysis_dir,\"photodraw_tracing\")\n",
    "ref_dir = os.path.join(analysis_dir, 'tracing_ref_400')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate shape + tracing stimuli for evaluation experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# generate reference shapes\n",
    "really_run_this = 0\n",
    "if really_run_this:\n",
    "    ref_path = []\n",
    "    for t in tracing:\n",
    "        print t\n",
    "        fname = os.path.join(ref_dir, '{}.png'.format(t))\n",
    "        img_ref = cv2.imread(fname)\n",
    "        img_ref = rsh.color_to_num(img_ref, threshold=0, white_background=False)\n",
    "        ofname = os.path.join(ref_dir, '{}_ref.png'.format(t))\n",
    "        cv2.imwrite(ofname, 255-img_ref*255)\n",
    "        ref_path.append(ofname)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Overlap the drawing on reference images\n",
    "iteration_name = ['CDM_photodraw_e1', 'cdm_run_v3', 'cdm_run_v4']\n",
    "dir_name = ['photodraw_e1', 'museumstation_v3', 'museumstation_v4']\n",
    "tracing = ['square', 'shape', 'this circle']\n",
    "overlap_dir = os.path.join(analysis_dir, 'tracing_overlap')\n",
    "if not os.path.exists(overlap_dir):\n",
    "    os.makedirs(overlap_dir)\n",
    "\n",
    "for di, dname in enumerate(dir_name):\n",
    "    iter_dir = os.path.join(overlap_dir, dname)\n",
    "    if not os.path.exists(iter_dir):\n",
    "        os.makedirs(iter_dir)\n",
    "        \n",
    "    current_data_dir = os.path.join(analysis_dir,\"tracing_{}\".format(iteration_name[di]))\n",
    "\n",
    "    # get tracings from the data folder\n",
    "    for ti, t in enumerate(tracing):\n",
    "            \n",
    "        if dname == 'photodraw_e1' and (t == 'square' or t == 'shape'):\n",
    "            t = 'this ' + t\n",
    "        t_dir = os.path.join(current_data_dir, t)\n",
    "        overlap_t = os.path.join(iter_dir, t)\n",
    "        \n",
    "        if not os.path.exists(overlap_t):\n",
    "                os.makedirs(overlap_t)\n",
    "                \n",
    "        if os.path.exists(t_dir):\n",
    "            for fname in os.listdir(t_dir):\n",
    "                if fname.startswith('age'):\n",
    "                    img_draw = os.path.join(current_data_dir, t_dir, fname)\n",
    "                    img_ref = ref_path[ti]\n",
    "\n",
    "                    draw = cv2.imread(img_draw).astype(int16)\n",
    "                    ref = cv2.imread(img_ref).astype(int16)\n",
    "                    img = ref\n",
    "                    img[np.sum(ref, axis=2)<255*3] = [150, 150, 150]\n",
    "                    img[np.sum(draw, axis=2)<255*3] = [40, 40, 170]\n",
    "\n",
    "\n",
    "                    cv2.imwrite(os.path.join(iter_dir,t, fname), img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### upload stims to s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## define AWS bucket name\n",
    "bucket_name = 'kiddraw-tracing-test'\n",
    "\n",
    "## define paths to tracing stimuli\n",
    "eval_stims_dir = os.path.join(tracing_dir,'tracing_eval_stims') ## unzipped tracing_eval.zip into the analysis dir\n",
    "experiment_list = ['museumstation_v3','museumstation_v4','photodraw_e1']\n",
    "shape_list = ['square','shape', 'circle']\n",
    "\n",
    "def deborkify_imlist(im_list):\n",
    "    im_list = [i for i in im_list if i != '.DS_Store']\n",
    "    im_list = [i for i in im_list if i[-3:]=='png']\n",
    "    return im_list\n",
    "\n",
    "def construct_full_paths(im_list,\n",
    "                         stims_dir = '../tracing_eval_stims',\n",
    "                         this_exp = 'museumstation_v3',\n",
    "                         this_shape = 'circle'):\n",
    "    base_path = os.path.join(stims_dir,this_exp,this_shape)\n",
    "    path_list = [os.path.join(base_path,this_im) for this_im in im_list]\n",
    "    return path_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import boto\n",
    "runThis = 1\n",
    "if runThis:\n",
    "    conn = boto.connect_s3()\n",
    "    b = conn.create_bucket(bucket_name) ### if bucket already exists, then get_bucket, else create_bucket\n",
    "    for exp_ind,this_exp in enumerate(experiment_list):\n",
    "        for shape_ind, this_shape in enumerate(shape_list):\n",
    "            im_list = os.listdir(os.path.join(eval_stims_dir,this_exp,this_shape))\n",
    "            im_list = deborkify_imlist(im_list)            \n",
    "            path_to_ims = construct_full_paths(im_list,\n",
    "                                               stims_dir=eval_stims_dir,\n",
    "                                               this_exp=this_exp,\n",
    "                                               this_shape=this_shape)\n",
    "            for im_ind, this_im in enumerate(path_to_ims):\n",
    "                clear_output(wait=True)\n",
    "                im_name = this_im.split('/')[-1]\n",
    "                k = b.new_key(im_name)\n",
    "                k.set_contents_from_filename(this_im)\n",
    "                k.set_acl('public-read')\n",
    "                print 'Uploading {} of {} | {}'.format(im_ind,len(path_to_ims),im_name)\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### build stimulus dictionary & upload metadata to mongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read in data from csv files\n",
    "cdm_v3 = pd.read_csv('MuseumStation_Tracing_Descriptives_cdm_run_v3.csv')\n",
    "cdm_v4 = pd.read_csv('MuseumStation_Tracing_Descriptives_cdm_run_v4.csv')\n",
    "photodraw = pd.read_csv('Photodraw_Tracing_Descriptives_CDM_photodraw_e1.csv')\n",
    "limit = 200\n",
    "overall = photodraw\n",
    "\n",
    "for t in tracing:\n",
    "    for a in range(2,11):\n",
    "        cdm_v3_tage = cdm_v3.loc[(cdm_v3['age'] == 'age{}'.format(a)) & (cdm_v3['category']== t)]\n",
    "        v3_size = cdm_v3_tage.shape[0]                 \n",
    "        if v3_size > limit:\n",
    "            overall = pd.concat([overall, cdm_v3_tage[:200]])\n",
    "            \n",
    "        else:\n",
    "            overall = pd.concat([overall, cdm_v3_tage]) \n",
    "            \n",
    "            cdm_v4_tage = cdm_v4.loc[(cdm_v4['age'] == 'age{}'.format(a)) & (cdm_v4['category']== t)]\n",
    "            \n",
    "            overall = pd.concat([overall, cdm_v4_tage[:limit-v3_size]])\n",
    "\n",
    "print overall.shape\n",
    "for t in tracing:\n",
    "    for a in range(2,11):\n",
    "        print t, a, overall.loc[(overall['age'] == 'age{}'.format(a)) & ( (overall['category'] == t) | (overall['category'] == 'this {}'.format(t)) )].shape\n",
    "\n",
    "overall = overall.drop(['filename', \"Unnamed: 0\"], axis=1)\n",
    "overall.reset_index(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "overall['exp_name'] = 0\n",
    "overall['iteration_name'] = 0\n",
    "overall['img_url'] = 0\n",
    "overall['number_rating_levels'] = 5\n",
    "overall['dynamic_rating'] = False\n",
    "overall['lower_bound'] = 'NaN'\n",
    "overall['upper_bound'] = 'NaN' \n",
    "\n",
    "for index, row in overall.iterrows():\n",
    "    sid = row['session_id']\n",
    "    if sid.startswith('CDM'):\n",
    "        overall.loc[index,'exp_name'] = 'photodraw'\n",
    "        overall.loc[index,'iteration_name'] = 'e1'\n",
    "    else:\n",
    "        overall.loc[index,'exp_name'] = 'museumstation'\n",
    "        overall.loc[index,'iteration_name'] = sid.split('_')[2][:2]\n",
    "    \n",
    "    fname = '{}_{}_{}.png'.format(row['age'], row['session_id'], row['category'])\n",
    "    exp_folder = overall.loc[index,'exp_name'] + '_' + overall.loc[index,'iteration_name']\n",
    "    overall.loc[index,'img_url'] = 'https://s3.amazonaws.com/tracing_overlap/{}/{}/{}'.format(exp_folder, row['category'], fname)\n",
    "\n",
    "overall = overall.drop('index', axis=1)\n",
    "overall.to_csv('tracing_eval_dict.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## convert csv file to json file\n",
    "import json\n",
    "overall = pd.read_csv('tracing_eval_dict.csv')\n",
    "stimdict = overall.to_dict(orient='records') \n",
    "with open('{}.js'.format('tracing_eval_dict'), 'w') as fout:\n",
    "    json.dump(stimdict, fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### next todo is to upload this JSON to initialize the new stimulus collection\n",
    "print('next todo is to upload this JSON to initialize the new stimulus collection...')\n",
    "import json\n",
    "J = json.loads(open('{}.js'.format(dataset_name),mode='ru').read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##assert len(J)==len(all_files)\n",
    "print 'dataset_name: {}'.format(dataset_name)\n",
    "print len(J)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set vars \n",
    "auth = pd.read_csv('auth.txt', header = None) # this auth.txt file contains the password for the sketchloop user\n",
    "pswd = auth.values[0][0]\n",
    "user = 'sketchloop'\n",
    "host = 'rxdhawkins.me' ## cocolab ip address\n",
    "\n",
    "# have to fix this to be able to analyze from local\n",
    "conn = pm.MongoClient('mongodb://sketchloop:' + pswd + '@127.0.0.1')\n",
    "db = conn['stimuli']\n",
    "coll = db[dataset_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## actually add data now to the database\n",
    "reallyRun = 1\n",
    "if reallyRun:\n",
    "    for (i,j) in enumerate(J):\n",
    "        if i%100==0:\n",
    "            print ('%d of %d' % (i,len(J)))\n",
    "        coll.insert_one(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## check how many records have been retrieved\n",
    "a = coll.find({'shuffler_ind':{'$gte':0}})\n",
    "numGames = []\n",
    "for rec in a:\n",
    "    numGames.append(len(rec['games']))\n",
    "b = np.array(numGames)\n",
    "print np.mean(b>0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
