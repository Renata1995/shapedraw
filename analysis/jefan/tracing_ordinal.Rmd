---
title: "Tracing Ordinal"
output: html_document
---

```{r}
library(tidyverse)
library(lme4)
library(groupdata2)
library(dplyr)
library(knitr) 
library(broom) 
#library(hydroGOF) 
library(MASS)
```
Goal: 
1. Run an image registration model on human rating to estimate the weights of shape error and spatial error
2. Use the estimated weights to get a good evaluation of the large tracing/copy dataset

Tracing analysis Summary:
1. Image Registration
2. Human Evaluation

#### Estimate the weights of shape and spatial errors on the tracing dataset

##### Load data and convert types
```{r}
raw = read.csv('tracing_ordinal_data.csv')
raw$category = factor(raw$category, levels = c('square', 'shape', 'circle'))
raw$has_ref = as.logical(raw$has_ref)
raw = raw[raw$has_ref==TRUE,]
raw[raw$human_norm_rating==-10.0, 'human_norm_rating'] = NA
raw[raw$human_rating==-10.0, 'human_rating'] = NA
raw[raw$button_pressed == -10.0, 'button_pressed'] = NA
write.csv(raw, 'tracing_raw.csv', row.names = FALSE)
```

```{r}
mdata = read.csv('tracing_raw.csv')
mdata$category = factor(mdata$category, levels = c('square', 'shape'))
mdata$button_pressed = factor(mdata$button_pressed, levels = c(0, 1, 2, 3, 4), ordered=TRUE)
mdata$has_ref = as.logical(mdata$has_ref)
mdata$norm_shape = scale(mdata$post_tran)
mdata$norm_spatial = scale(mdata$spatial)
rater_data = mdata[!is.na(mdata$button_pressed),]
```

##### General distribution of the rating data
```{r}
for (t in c('square', 'shape')){
  for (i in seq(2, 10, by=1) ){
    sub = subset(rater_data , category == t & age == i)
    print (c(t, i, nrow(sub)) )
  }
}
```

##### Split data in 20/80 test/training
```{r}
parts <- partition(rater_data, p = 0.2, cat_col = c("age", "category"))
# parts <- partition(rater_data, p = 0.2, cat_col = c("category"))
#parts = partition(rater_data, p=0.2)
test_set <- parts[[1]]
train_set <- parts[[2]]

# train_set %>% 
# count(age, category) %>% 
# kable(align='c')
# 
# test_set %>% 
# count(age, category) %>% 
# kable(align='c')
```

##### Cross Validation
```{r}
train_set <- fold(train_set, k=5, cat_col = c("age", "category"))
#train_set = fold(train_set, k=2)
# train_set <- fold(train_set, k=3, cat_col = c("category"))
train_set <- train_set[order(train_set$.folds),]

# train_set %>% 
# count(age, category, .folds) %>% 
# kable(align='c')
```


```{r}
mdata 
```

```{r}
newdat %>%
  rename(very_poor='0') %>%
  rename(poor='1') %>%
  rename(okay='2') %>%
  rename(good='3') %>%
  rename(very_good='4') %>%
  filter(human_rating==0) %>%
  mutate(likelihood = case_when(human_rating==0 ~ very_poor,
                                human_rating==1 ~ poor,
                                human_rating==2 ~ okay,
                                human_rating==3 ~ good,
                                human_rating==4 ~ very_good,
                                is.nan(human_rating) ~ NaN)) 
```


```{r}
crossvalidate <- function(data, k, m, dependent){
  performances <- c()
  for (fold in 1:k){
    testing_set <- data[data$.folds == fold,]
    training_set <- data[data$.folds != fold,]
    model <-  polr(m, training_set, Hess=TRUE)

    # pred_train <- cbind(pred_train, predict(model, training_set, type = "probs"))
    # error_train = 0 
    # for (i in pred_train){
    #   hr = i.button_pressed
    #   error_train = error_train + 
    # }

    pred_rating <- predict(model, testing_set) 
    error = mean(as.numeric(pred_rating) != as.numeric(testing_set$button_pressed))
    performances[fold] <- error
    # print (paste0(fold, "  training Error: ", error_train, "  hold out Error: ", error))
    
  }

  return (performances)

}
```

```{r}
m1 = "button_pressed ~  category + norm_shape * norm_spatial"
result = crossvalidate(train_set, k=5, m=m1, dependent='button_pressed')
print (paste0("Average MSE across all folds: ", mean(result)))
```

##### Apply the model on the test set and examine the MSE
```{r}
model1 = polr(m1, train_set, Hess=TRUE)
predicted = predict(model1, test_set, type = "probs")
newdat = cbind(test_set, predict(model1, test_set, type = "probs"))
#diff = mean(as.numeric(predicted) != as.numeric(test_set$button_pressed))

summary(model1)
#diff
#table(test_set$button_pressed, predicted)
```

##### Apply the model on tracing and copying images without human ratings
```{r}
model1 = polr(m1, rater_data, Hess=TRUE) # Apply the model on the full training set
final_set = mdata[is.na(mdata$human_rating), ]
predicted = predict(model1, final_set)

summary(model1)
```

##### Output the csv file
```{r}
all_data = read.csv('museumstation_tracing_ncc.csv')
all_data$category = factor(all_data$category, levels = c('square', 'shape', 'circle'))
all_data$has_ref = as.logical(all_data$has_ref)
all_data = all_data[all_data$has_ref==TRUE,]
all_data = subset(all_data, select = -c(human_norm_rating, human_rating))
all_data$norm_shape = scale(all_data$post_tran)
all_data$norm_spatial = scale(all_data$spatial)

all_data$human_norm_rating = predict(model1, all_data)
write.csv(all_data, file = "tracing_eval_ordinal.csv")
```

```{r}
for (t in c('square', 'shape')){
  for (i in seq(2, 10, by=1) ){
    for (j in seq(0, 4, by=1)){
      sub = subset(all_data, category == t & age == i & human_norm_rating == j)
      print (c(t, i, j, nrow(sub)) )
    }
  }
}
```

